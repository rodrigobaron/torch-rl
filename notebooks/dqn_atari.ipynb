{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb08f0a9-12b3-495a-b31c-3de241fa906e",
   "metadata": {},
   "source": [
    "## Setup arguments\n",
    "\n",
    "This automatically parse arguments as jupyter inputs making it more user friendly :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed21c841-2841-468e-8705-d2fe7528cf71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T02:51:58.543320Z",
     "iopub.status.busy": "2022-10-03T02:51:58.542399Z",
     "iopub.status.idle": "2022-10-03T02:51:59.685344Z",
     "shell.execute_reply": "2022-10-03T02:51:59.684721Z",
     "shell.execute_reply.started": "2022-10-03T02:51:58.543236Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18af3ea61e14374a4a2e0728a1a7b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1, description='seed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860be89055484f66b25e376f0d113997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='torch_deterministic', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82225c6159a745a6bd11a8c18b11c711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='cuda', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456223f4550f462591326ca9ec92a1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='capture_video', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42521a2c39a240b2a6e26ddc41f85eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='BreakoutNoFrameskip-v4', description='env_id')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9779c5a5544176820a8f33433ba255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=10000000, description='total_timesteps')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325066b13fe244b7bf8db7c80a0f9a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.0001, description='learning_rate')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f0096a930e4ffea06448b04f4356fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1000000, description='buffer_size')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09edd0781ad94fc59758df5b0e7a1dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.99, description='gamma')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec7d72d9aa6489488c9ff20785eeac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=1000, description='target_network_frequency')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a9e35b1b484975b3351987af6363f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=32, description='batch_size')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245b827130fd46c0be6bd4759b554e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=1.0, description='start_e')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f323a8987234d6292cfceae97d3f5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.01, description='end_e')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aac6b7fc8ff4566befbeb58f2011e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatText(value=0.1, description='exploration_fraction')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be39ca9202f34022ba1d230cf77827b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=8000, description='learning_starts')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c05850070354c65a8ca39cf927a1a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=4, description='train_frequency')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from distutils.util import strtobool\n",
    "\n",
    "from jupyter_utils import JupyterArgumentParser\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = JupyterArgumentParser()\n",
    "    parser.add_argument(\"--seed\", type=int, default=1,\n",
    "        help=\"seed of the experiment\")\n",
    "    parser.add_argument(\"--torch-deterministic\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, `torch.backends.cudnn.deterministic=False`\")\n",
    "    parser.add_argument(\"--cuda\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"if toggled, cuda will be enabled by default\")\n",
    "    parser.add_argument(\"--capture-video\", type=lambda x: bool(strtobool(x)), default=True, nargs=\"?\", const=True,\n",
    "        help=\"whether to capture videos of the agent performances (check out `videos` folder)\")\n",
    "    parser.add_argument(\"--env-id\", type=str, default=\"BreakoutNoFrameskip-v4\",\n",
    "        help=\"the id of the environment\")\n",
    "    parser.add_argument(\"--total-timesteps\", type=int, default=10000000,\n",
    "        help=\"total timesteps of the experiments\")\n",
    "    parser.add_argument(\"--learning-rate\", type=float, default=1e-4,\n",
    "        help=\"the learning rate of the optimizer\")\n",
    "    parser.add_argument(\"--buffer-size\", type=int, default=1000000,\n",
    "        help=\"the replay memory buffer size\")\n",
    "    parser.add_argument(\"--gamma\", type=float, default=0.99,\n",
    "        help=\"the discount factor gamma\")\n",
    "    parser.add_argument(\"--target-network-frequency\", type=int, default=1000,\n",
    "        help=\"the timesteps it takes to update the target network\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=32,\n",
    "        help=\"the batch size of sample from the reply memory\")\n",
    "    parser.add_argument(\"--start-e\", type=float, default=1,\n",
    "        help=\"the starting epsilon for exploration\")\n",
    "    parser.add_argument(\"--end-e\", type=float, default=0.01,\n",
    "        help=\"the ending epsilon for exploration\")\n",
    "    parser.add_argument(\"--exploration-fraction\", type=float, default=0.10,\n",
    "        help=\"the fraction of `total-timesteps` it takes from start-e to go end-e\")\n",
    "    parser.add_argument(\"--learning-starts\", type=int, default=8000,\n",
    "        help=\"timestep to start learning\")\n",
    "    parser.add_argument(\"--train-frequency\", type=int, default=4,\n",
    "        help=\"the frequency of training\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "parser = get_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de7812-47cd-4b73-a015-fa3bc6decb72",
   "metadata": {},
   "source": [
    "## Setup wrappers\n",
    "\n",
    "Use preprocessing wrappers to transfom the inputs according to baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eebc8f65-d3ba-40f5-8c0e-a6486e3e5074",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:35:34.290244Z",
     "iopub.status.busy": "2022-10-03T03:35:34.289285Z",
     "iopub.status.idle": "2022-10-03T03:35:34.313324Z",
     "shell.execute_reply": "2022-10-03T03:35:34.312521Z",
     "shell.execute_reply.started": "2022-10-03T03:35:34.290160Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from atari import make_atari_env\n",
    "from utils import seed_everything\n",
    "from buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08610d0-aa6c-4dbe-8cf1-8b088e560c9b",
   "metadata": {},
   "source": [
    "Parse experiment arguments.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9081e3e1-623c-40d0-9eb2-ecf339fa0328",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:13:23.591719Z",
     "iopub.status.busy": "2022-10-03T03:13:23.591303Z",
     "iopub.status.idle": "2022-10-03T03:13:23.609444Z",
     "shell.execute_reply": "2022-10-03T03:13:23.608503Z",
     "shell.execute_reply.started": "2022-10-03T03:13:23.591694Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|param=value|\n",
      "|-|-|\n",
      "|seed=1|\n",
      "|torch_deterministic=True|\n",
      "|cuda=True|\n",
      "|capture_video=True|\n",
      "|env_id=BreakoutNoFrameskip-v4|\n",
      "|total_timesteps=10000000|\n",
      "|learning_rate=0.0001|\n",
      "|buffer_size=1000000|\n",
      "|gamma=0.99|\n",
      "|target_network_frequency=1000|\n",
      "|batch_size=32|\n",
      "|start_e=1.0|\n",
      "|end_e=0.01|\n",
      "|exploration_fraction=0.1|\n",
      "|learning_starts=8000|\n",
      "|train_frequency=4|\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "print(\"|param=value|\\n|-|-|\\n%s\" % (\"\\n\".join([f\"|{key}={value}|\" for key, value in vars(args).items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b417f3a-206d-4624-85fb-62789374bb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:00:06.709722Z",
     "iopub.status.busy": "2022-10-03T03:00:06.708806Z",
     "iopub.status.idle": "2022-10-03T03:00:06.752046Z",
     "shell.execute_reply": "2022-10-03T03:00:06.750898Z",
     "shell.execute_reply.started": "2022-10-03T03:00:06.709638Z"
    }
   },
   "outputs": [],
   "source": [
    "run_name = f\"{args.env_id}__dqn__{args.seed}__{int(time.time())}\" \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and args.cuda else \"cpu\")\n",
    "seed_everything(args.seed, args.torch_deterministic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fffc90-d838-4b3d-96f0-683ea7ddd01d",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cb7cba57-366e-412e-8eb6-42b9c7fec5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:15:39.596137Z",
     "iopub.status.busy": "2022-10-03T03:15:39.595207Z",
     "iopub.status.idle": "2022-10-03T03:15:39.936252Z",
     "shell.execute_reply": "2022-10-03T03:15:39.935594Z",
     "shell.execute_reply.started": "2022-10-03T03:15:39.596053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "envs = gym.vector.SyncVectorEnv([make_atari_env(args.env_id, args.seed, 0, args.capture_video, run_name)])\n",
    "assert isinstance(envs.single_action_space, gym.spaces.Discrete), \"only discrete action space is supported\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d229b6b-efac-43bd-818f-74c15f118f9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:17:34.254488Z",
     "iopub.status.busy": "2022-10-03T03:17:34.254047Z",
     "iopub.status.idle": "2022-10-03T03:17:34.270359Z",
     "shell.execute_reply": "2022-10-03T03:17:34.269512Z",
     "shell.execute_reply.started": "2022-10-03T03:17:34.254464Z"
    }
   },
   "source": [
    "## Few examples\n",
    "\n",
    "Show few env steps and the transformation input.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b73cc-a012-40a0-a735-65f4090f723a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "441336c2-97c3-49c9-b12a-21cfd4a06df3",
   "metadata": {},
   "source": [
    "## Define Q Network\n",
    "\n",
    "The Q network is .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba819a6e-0552-4d22-bcca-768c22651999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:24:47.585336Z",
     "iopub.status.busy": "2022-10-03T03:24:47.584502Z",
     "iopub.status.idle": "2022-10-03T03:24:47.607415Z",
     "shell.execute_reply": "2022-10-03T03:24:47.606714Z",
     "shell.execute_reply.started": "2022-10-03T03:24:47.585300Z"
    }
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, 8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, env.single_action_space.n),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398bf469-74ef-4f94-9218-8a94369e5f70",
   "metadata": {},
   "source": [
    "## Setup DQN training\n",
    "\n",
    "Setup QNetwork and TargetNetwork along with ReplayBuffer, Optimization and schedules.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b09d21e9-a479-4470-ae1d-24ff5b806b48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:28:57.592735Z",
     "iopub.status.busy": "2022-10-03T03:28:57.592458Z",
     "iopub.status.idle": "2022-10-03T03:28:57.614357Z",
     "shell.execute_reply": "2022-10-03T03:28:57.613560Z",
     "shell.execute_reply.started": "2022-10-03T03:28:57.592711Z"
    }
   },
   "outputs": [],
   "source": [
    "def linear_schedule(start_e: float, end_e: float, duration: int, t: int):\n",
    "    slope = (end_e - start_e) / duration\n",
    "    return max(slope * t + start_e, end_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a025abed-7847-4939-b9d5-beae1310078a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:24:57.592971Z",
     "iopub.status.busy": "2022-10-03T03:24:57.592427Z",
     "iopub.status.idle": "2022-10-03T03:24:57.642642Z",
     "shell.execute_reply": "2022-10-03T03:24:57.641918Z",
     "shell.execute_reply.started": "2022-10-03T03:24:57.592945Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/notebooks/buffers.py:374: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 28.24GB > 4.29GB\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "q_network = QNetwork(envs).to(device)\n",
    "optimizer = optim.Adam(q_network.parameters(), lr=args.learning_rate)\n",
    "target_network = QNetwork(envs).to(device)\n",
    "target_network.load_state_dict(q_network.state_dict())\n",
    "\n",
    "rb = ReplayBuffer(\n",
    "    args.buffer_size,\n",
    "    envs.single_observation_space,\n",
    "    envs.single_action_space,\n",
    "    device,\n",
    "    optimize_memory_usage=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dde87068-f252-4635-ba0e-5b4e230fe0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:43:46.185187Z",
     "iopub.status.busy": "2022-10-03T03:43:46.183662Z",
     "iopub.status.idle": "2022-10-03T03:43:47.308233Z",
     "shell.execute_reply": "2022-10-03T03:43:47.307161Z",
     "shell.execute_reply.started": "2022-10-03T03:43:46.185061Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(obs, global_step):\n",
    "    # ALGO LOGIC: put action logic here\n",
    "    epsilon = linear_schedule(args.start_e, args.end_e, args.exploration_fraction * args.total_timesteps, global_step)\n",
    "    if random.random() < epsilon:\n",
    "        actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "    else:\n",
    "        q_values = q_network(torch.Tensor(obs).to(device))\n",
    "        actions = torch.argmax(q_values, dim=1).cpu().numpy()\n",
    "\n",
    "    # TRY NOT TO MODIFY: execute the game and log data.\n",
    "    next_obs, rewards, dones, infos = envs.step(actions)\n",
    "\n",
    "    # TRY NOT TO MODIFY: record rewards for plotting purposes\n",
    "    for info in infos:\n",
    "        if \"episode\" in info.keys():\n",
    "            print(f\"global_step={global_step}, episodic_return={info['episode']['r']}\")\n",
    "            # writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "            # writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "            # writer.add_scalar(\"charts/epsilon\", epsilon, global_step)\n",
    "            break\n",
    "\n",
    "    # TRY NOT TO MODIFY: save data to reply buffer; handle `terminal_observation`\n",
    "    real_next_obs = next_obs.copy()\n",
    "    for idx, d in enumerate(dones):\n",
    "        if \"terminal_observation\" in infos[idx].keys() and d:\n",
    "            real_next_obs[idx] = infos[idx][\"terminal_observation\"]\n",
    "    rb.add(obs, real_next_obs, actions, rewards, dones)\n",
    "\n",
    "    # TRY NOT TO MODIFY: CRUCIAL step easy to overlook\n",
    "    # obs = next_obs\n",
    "\n",
    "    # ALGO LOGIC: training.\n",
    "    if global_step > args.learning_starts and global_step % args.train_frequency == 0:\n",
    "        data = rb.sample(args.batch_size)\n",
    "        with torch.no_grad():\n",
    "            target_max, _ = target_network(data.next_observations).max(dim=1)\n",
    "            td_target = data.rewards.flatten() + args.gamma * target_max * (1 - data.dones.flatten())\n",
    "        old_val = q_network(data.observations).gather(1, data.actions).squeeze()\n",
    "        loss = F.mse_loss(td_target, old_val)\n",
    "\n",
    "        # if global_step % 100 == 0:\n",
    "            # writer.add_scalar(\"losses/td_loss\", loss, global_step)\n",
    "            # writer.add_scalar(\"losses/q_values\", old_val.mean().item(), global_step)\n",
    "            # print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "            # writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "        # optimize the model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update the target network\n",
    "        if global_step % args.target_network_frequency == 0:\n",
    "            target_network.load_state_dict(q_network.state_dict())\n",
    "    return next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d285d485-4a38-4552-ab6a-0438ddbe04a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T03:43:47.630550Z",
     "iopub.status.busy": "2022-10-03T03:43:47.630085Z",
     "iopub.status.idle": "2022-10-03T03:44:08.331432Z",
     "shell.execute_reply": "2022-10-03T03:44:08.330203Z",
     "shell.execute_reply.started": "2022-10-03T03:43:47.630511Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=255, episodic_return=4.0\n",
      "global_step=416, episodic_return=1.0\n",
      "global_step=559, episodic_return=1.0\n",
      "global_step=846, episodic_return=4.0\n",
      "global_step=961, episodic_return=0.0\n",
      "global_step=1247, episodic_return=4.0\n",
      "global_step=1456, episodic_return=2.0\n",
      "global_step=1571, episodic_return=0.0\n",
      "global_step=1759, episodic_return=2.0\n",
      "global_step=1920, episodic_return=1.0\n",
      "global_step=2033, episodic_return=0.0\n",
      "global_step=2144, episodic_return=0.0\n",
      "global_step=2259, episodic_return=0.0\n",
      "global_step=2374, episodic_return=0.0\n",
      "global_step=2612, episodic_return=3.0\n",
      "global_step=2725, episodic_return=0.0\n",
      "global_step=2838, episodic_return=0.0\n",
      "global_step=3157, episodic_return=5.0\n",
      "global_step=3270, episodic_return=0.0\n",
      "global_step=3385, episodic_return=0.0\n",
      "global_step=3542, episodic_return=1.0\n",
      "global_step=3653, episodic_return=0.0\n",
      "global_step=3766, episodic_return=0.0\n",
      "global_step=3877, episodic_return=0.0\n",
      "global_step=3992, episodic_return=0.0\n",
      "global_step=4134, episodic_return=1.0\n",
      "global_step=4247, episodic_return=0.0\n",
      "global_step=4405, episodic_return=1.0\n",
      "global_step=4520, episodic_return=0.0\n",
      "global_step=4663, episodic_return=1.0\n",
      "global_step=4867, episodic_return=2.0\n",
      "global_step=5092, episodic_return=3.0\n",
      "global_step=5251, episodic_return=1.0\n",
      "global_step=5529, episodic_return=4.0\n",
      "global_step=5642, episodic_return=0.0\n",
      "global_step=5853, episodic_return=2.0\n",
      "global_step=5968, episodic_return=0.0\n",
      "global_step=6131, episodic_return=1.0\n",
      "global_step=6319, episodic_return=2.0\n",
      "global_step=6432, episodic_return=0.0\n",
      "global_step=6545, episodic_return=0.0\n",
      "global_step=6714, episodic_return=2.0\n",
      "global_step=6829, episodic_return=0.0\n",
      "global_step=6989, episodic_return=1.0\n",
      "global_step=7247, episodic_return=3.0\n",
      "global_step=7534, episodic_return=4.0\n",
      "global_step=7693, episodic_return=1.0\n",
      "global_step=7898, episodic_return=2.0\n",
      "global_step=8011, episodic_return=0.0\n",
      "global_step=8166, episodic_return=1.0\n",
      "global_step=8356, episodic_return=2.0\n",
      "global_step=8469, episodic_return=0.0\n",
      "global_step=8804, episodic_return=5.0\n",
      "global_step=9015, episodic_return=2.0\n",
      "global_step=9189, episodic_return=2.0\n",
      "global_step=9304, episodic_return=0.0\n",
      "global_step=9415, episodic_return=0.0\n",
      "global_step=9603, episodic_return=2.0\n",
      "global_step=9995, episodic_return=9.0\n",
      "global_step=10106, episodic_return=0.0\n",
      "global_step=10248, episodic_return=1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m obs \u001b[38;5;241m=\u001b[39m envs\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m global_step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mtotal_timesteps):\n\u001b[0;32m----> 3\u001b[0m     next_obs \u001b[38;5;241m=\u001b[39m train_step(obs, global_step)\n\u001b[1;32m      4\u001b[0m     obs \u001b[38;5;241m=\u001b[39m next_obs\n\u001b[1;32m      6\u001b[0m envs\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn [84], line 34\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(obs, global_step)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# TRY NOT TO MODIFY: CRUCIAL step easy to overlook\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# obs = next_obs\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# ALGO LOGIC: training.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_step \u001b[38;5;241m>\u001b[39m args\u001b[38;5;241m.\u001b[39mlearning_starts \u001b[38;5;129;01mand\u001b[39;00m global_step \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39mtrain_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 34\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mrb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     36\u001b[0m         target_max, _ \u001b[38;5;241m=\u001b[39m target_network(data\u001b[38;5;241m.\u001b[39mnext_observations)\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/app/notebooks/buffers.py:416\u001b[0m, in \u001b[0;36mReplayBuffer.sample\u001b[0;34m(self, batch_size, env)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    415\u001b[0m     batch_inds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos, size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/notebooks/buffers.py:431\u001b[0m, in \u001b[0;36mReplayBuffer._get_samples\u001b[0;34m(self, batch_inds, env)\u001b[0m\n\u001b[1;32m    422\u001b[0m     next_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_obs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_observations[batch_inds, \u001b[38;5;241m0\u001b[39m, :], env)\n\u001b[1;32m    424\u001b[0m data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_obs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservations[batch_inds, \u001b[38;5;241m0\u001b[39m, :], env),\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[batch_inds, \u001b[38;5;241m0\u001b[39m, :],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_reward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[batch_inds], env),\n\u001b[1;32m    430\u001b[0m )\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ReplayBufferSamples(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/app/notebooks/buffers.py:303\u001b[0m, in \u001b[0;36mBaseBuffer.to_torch\u001b[0;34m(self, array, copy)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03mConvert a numpy array to a PyTorch tensor.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03mNote: it copies the data by default\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m:return:\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mas_tensor(array)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "obs = envs.reset()\n",
    "for global_step in range(args.total_timesteps):\n",
    "    next_obs = train_step(obs, global_step)\n",
    "    obs = next_obs\n",
    "\n",
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8044b-271f-4a61-9d9a-4555c2c472a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
